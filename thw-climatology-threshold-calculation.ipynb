{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating mean climatology and threshold of daily tmax for Australia (based on Ritwik Misra's MHW code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the code required to calculate the mean climatology and 90th percentile of daily maximum temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and define functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the required modules, and initialize a dask cluster for parallel computing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-19.10/lib/python3.6/site-packages/distributed/worker.py:485: UserWarning: The local_dir keyword has moved to local_directory\n",
      "  warnings.warn(\"The local_dir keyword has moved to local_directory\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://10.0.64.15/16484/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.0.64.15/16484/1:8787/status' target='_blank'>http://10.0.64.15/16484/1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>33.67 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://10.0.64.15/16484/1' processes=1 threads=8, memory=33.67 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask as da\n",
    "from dask.distributed import LocalCluster, Client\n",
    "from datetime import date\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "import xarray as xr\n",
    "%pylab inline\n",
    "local_dir = \"/g/data/e14/cp3790/dask-workers\" #Replace this with your local directory \n",
    "cluster = LocalCluster(processes=False, local_dir=local_dir)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function created by Guillaume Serazin to reshape data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(da):\n",
    "        da_groupby = list(da.groupby('time.dayofyear'))\n",
    "        dayofyear = []\n",
    "        da_dayofyear = []\n",
    "        for item in list(da_groupby):\n",
    "            dayofyear.append(item[0])\n",
    "            da_tmp = item[1]\n",
    "            da_tmp['time'] = da_tmp['time.year']\n",
    "            da_tmp = da_tmp.rename({'time': 'year'})\n",
    "            da_tmp = da_tmp.assign_coords(dayofyear=item[0])\n",
    "            da_dayofyear.append(da_tmp)\n",
    "        da_reshaped = xr.concat(da_dayofyear, dim='dayofyear')\n",
    "        return da_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening files and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('/g/data/e14/cp3790/Charuni/ERA5-new/era5_dailytmax_*.nc'))\n",
    "\n",
    "obs_aus = (xr.open_mfdataset(files, combine='nested', concat_dim='time', chunks={'latitude': 10})\n",
    "           .sel(time=slice('1983', '2012'), longitude=slice(113, 154), latitude=slice(-10, -44)))\n",
    "#baseline period for my calculation is 1983-2012\n",
    "baseline_tmax = obs_aus[\"dmax\"]\n",
    "baseline_tmax.attrs['units'] = 'deg C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and smoothing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the data ready to have a rolling mean performed upon it. This is performed in the reshape_data function (created by Guillaume Serazin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_tmax = reshape_data(baseline_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is 'circularized', making rolling window processes possible for first and last days.\n",
    "\n",
    "In my analysis, I have retained the leap days, but if you wanted to drop them -->\n",
    "#tmax_reshaped = reshaped_tmax.isel(dayofyear = slice(0,-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = reshaped_tmax[:31] # the first 31 days \n",
    "start['dayofyear'] = range(366,397) # the first 31 days will be 'stitched' to the last 31 days \n",
    "end = reshaped_tmax[-31:] # the last 31 days \n",
    "end['dayofyear'] = range(-30, 1) # the last 31 days will be 'stitched' to the first 31 days \n",
    "circular_tmax = xr.concat([end, reshaped_tmax, start], dim = 'dayofyear').chunk({'dayofyear' : 31})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating mean climatology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is smoothed once using a 15 day rolling window, and subsequently by a 31-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tmax = circular_tmax.mean('year')\n",
    "tmax_climatology_smooth = raw_tmax.rolling(dayofyear = 15, center = True).mean() \n",
    "tmax_climatology_smoother = tmax_climatology_smooth.rolling(dayofyear = 31, center = True).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_climatology = tmax_climatology_smoother.isel(dayofyear = slice(31,-31)) # drop the first and last 31 days "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a netCDF file to store the mean climatology values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset({'climatology': tmax_climatology}).to_netcdf('/g/data/e14/cp3790/Charuni/climatology-australia.nc',\n",
    "                                              encoding={'climatology': \n",
    "                                                        {'chunksizes': (100, tmax_climatology.shape[1], tmax_climatology.shape[2]),\n",
    "                                                         'zlib': True,\n",
    "                                                         'shuffle': True, \n",
    "                                                         'complevel': 2}})  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike in mean climatology (in which you get the rolling mean in a straightforward way) this uses np.nanpercentile,\n",
    "so we have to get a rolling construct first and then do the 90th percentile calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "percRolling = circular_tmax.rolling(dayofyear=15, center=True).construct('rolling_days')\n",
    "# This takes in the circular_tmax, performs the percentile calculation, then creates a new dimension and coordinate names \n",
    "# to prepapre the data for the final output\n",
    "stacked = percRolling.stack(z = ('rolling_days', 'year'))\n",
    "rawPerc_data = da.array.apply_along_axis(np.nanpercentile, stacked.get_axis_num('z'), stacked.data, 90)\n",
    "tmax_coords = circular_tmax.coords\n",
    "new_coords = {name : tmax_coords[name] for name in tmax_coords if name != 'year'}\n",
    "new_dims = [name for name in circular_tmax.dims if name != 'year']\n",
    "rawPerc = xr.DataArray(rawPerc_data, coords = new_coords, dims = new_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final rolling mean over a month (smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data smoothed, DONE.\n",
      "First and last 31 days sliced\n"
     ]
    }
   ],
   "source": [
    "tmax_threshold = rawPerc.rolling(dayofyear=31, center = True).mean()\n",
    "print(\"Data smoothed, DONE.\")\n",
    "tmax_threshold = tmax_threshold.isel(dayofyear = slice(31,-31))\n",
    "print(\"First and last 31 days sliced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a netCDF file to store the threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset({'threshold': tmax_threshold}).to_netcdf('/g/data/e14/cp3790/Charuni/threshold-australia.nc',\n",
    "                                              encoding={'threshold': \n",
    "                                                        {'chunksizes': (100, tmax_threshold.shape[1], tmax_threshold.shape[2]),\n",
    "                                                         'zlib': True,\n",
    "                                                         'shuffle': True, \n",
    "                                                         'complevel': 2}})  "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-19.10]",
   "language": "python",
   "name": "conda-env-analysis3-19.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "391.85px",
    "left": "1249px",
    "right": "20px",
    "top": "11px",
    "width": "347.333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
